#Atividade Avaliativa 01 - Machine Learning

##Aluno: OtÃƒÂ¡vio Augusto Alves Coelho
##Professor: Neylson Crepalde
##Curso: CiÃƒÂªncias de Dados


## ExercÃ­cio 1 [8]

if (! "ISLR" %in% installed.packages()) install.packages("ISLR")
if (! "MASS" %in% installed.packages()) install.packages("MASS")
if (! "dplyr" %in% installed.packages()) install.packages("dplyr")
if (! "ggplot2" %in% installed.packages()) install.packages("ggplot2")
if (! "readr" %in% installed.packages()) install.packages("readr")
if (! "texreg" %in% installed.packages()) install.packages("texreg")

#carregando a biblioteca library(ISLR), onde estÃƒÂ¡ o banco de dados Auto, e as outras bibliotecas
#estatÃƒ­sticas necessÃƒÂ¡rias para resoluÃƒÂ§ÃƒÂ£o dos exercÃƒ­cios.

library(ISLR)
library(readr)
library(dplyr)
library(texreg)
library(ggplot2)

#realizando a regressÃƒÂ£o linear em que mpg ÃƒÂ© o predicto e o horsepower ÃƒÂ© o preditor

str(Auto)
reg1 = lm(mpg ~ horsepower, data = Auto)
summary(reg1)


## a) I - como se observa, o p-valor ÃƒÂ© muito pequeno, menor que 0.05, 
# o que indica que hÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o
#estatisticamente vÃƒÂ¡lida entre ambos.
## II - como o p-valor ÃƒÂ© prÃƒÂ³ximo de 0, menor do que 0.05,
# podemos dizer que a correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© forte. Ao mesmo tempo, pelo valor do 
# Multiple R-squared, que ÃƒÂ© de 0.6059, podemos dizer que o poder explicativo do modelo ÃƒÂ© de 60,59%.
## III - como se observa pelo valor negativo do coeficiente, 
# temos uma correlaÃƒÂ§ÃƒÂ£o negativa entre o horsepower e o mpg, o que indica que o aumento de 
# horsepower significa uma diminuiÃƒÂ§ÃƒÂ£o no nÃƒÂºmero de mpg (milhas por galÃƒÂ£o).
## IV -  


predict(reg1, data.frame(horsepower=c(98)), interval="confidence")
predict(reg1, data.frame(horsepower=c(98)), interval="prediction")

## b) 

plot(mpg ~ horsepower, data=Auto)
abline(reg1, col="red", lwd = 2)


## c)

#usamos o comando par(mfrow=c(2,2)) que irÃƒÂ¡ dividir a tela de print em quatro partes
#onde 4 grÃƒÂ¡ficos distintos serÃƒÂ£o plotados.

par(mfrow=c(2,2))
plot(reg1)

#como se observa hÃƒÂ¡ possibilidade de a correlaÃƒÂ§ÃƒÂ£o entre as variÃƒÂ¡veis nÃƒÂ£o ser
#linear;


## ExerÃƒ­cio 2 [9]

#a) produzindo uma scatterbox plot que inclua todas as variÃƒÂ¡veis contidas no
#data set Auto

data(Auto)
pairs(Auto)

##b) 

cor(subset(Auto, select= -name))

##c) 

str(Auto)
reg2 = lm(mpg ~ cylinders + displacement + horsepower + weight + acceleration + year + origin, data=Auto)
summary(reg2)

## I) Sim, hÃƒÂ¡ relaÃƒÂ§ÃƒÂ£o. NÃƒÂ£o hÃƒÂ¡ relaÃƒÂ§ÃƒÂ£o entre o predicto e todos os preditores. Como se observa, hÃƒÂ¡ alguns valores para o 
#p-valor acima de 0.05, como para cylinders, horsepower, acceleration e origin.

## II) O modelo aponta correlaÃƒÂ§ÃƒÂ£o estatÃƒ­stica significativa para displacement, weight, year e origin.

## III) O coeficiente positivo de 0.75 aponta que a cada ano hÃƒÂ¡ um aumento de milhas por galÃƒÂ£o,
#isto ÃƒÂ©, que o carro se torna mais econÃƒÂ´mico, jÃƒÂ¡ que consegue andar mais milhas com um galÃƒÂ£o.

## d) 
par(mfrow=c(2,2))
plot(reg2)

# os resÃƒ­duos apontam alguns outliers, especialmente acima da curva. O leverage plot aponta observaÃƒÂ§ÃƒÂµes
## com leverage alto, como se observa nos pontos distribuÃƒ­dos em torno do valor 4 (sendo que 
## a maior parte dos valores estÃƒÂ¡ entre -2 e 2).



## ExercÃƒ­cio 3 [10]

data("Carseats")
head(Carseats)
str(Carseats)

# a)

reg3 = lm(Sales ~ Population + Urban + US, data = Carseats)
summary(reg3)

# b) a partir da operacionalizaÃƒÂ§ÃƒÂ£o da correlaÃƒÂ§ÃƒÂ£o linear, observa-se que nÃƒÂ£o hÃƒÂ¡ correlaÃƒÂ§ÃƒÂ£o estatisticamente
#vÃƒÂ¡lida entre todos os valores. Os p-valores para Population e Urban sÃƒÂ£o maiores que 0.05, indicando sua 
#ausÃƒÂªncia de correlaÃƒÂ§ÃƒÂ£o com as Vendas. Ao mesmo tempo, contudo, o p-valor apresentado para US aponta uma correlaÃƒÂ§ÃƒÂ£o 
#significativa entre esta variÃƒÂ¡vel e as vendas. Nesse sentido, observa-se que hÃƒÂ¡ uma relaÃƒÂ§ÃƒÂ£o entre a localizaÃƒÂ§ÃƒÂ£o 
#da loja e o nÃƒÂºmero de vendas. Se a loja onde a venda foi realizada estÃƒÂ¡ nos EUA, espera-se
#um aumento de 1036 unidades vendidas.

## c) 

# Sales = 0.0007Pop - 0.1341Urbanyes + 1.036USYes + 6.72

## d) Posso rejeitar a hipÃƒÂ³tese nula apenas para a variÃƒÂ¡vel USYes, jÃƒÂ¡ que seu p-valor
# ÃƒÂ© menor do que 0.05.

## e) 

reg4 = lm(Sales ~ US, data=Carseats)
summary(reg4)


## f) Ambas sÃƒÂ£o semelhantes, embora o poder explicativo da segunda seja maior, jÃƒÂ¡ que esta
## possui um Multiple R-squared (para regressÃƒÂµes lineares simples) maior do 
# que o Adjusted R-squared (para correlaÃƒÂ§ÃƒÂµes mÃƒÂºltiplas) da segunda. Ao mesmo tempo,
# por ser mais simples, possuindo menos variÃƒÂ¡veis, preferimos ela em relaÃƒÂ§ÃƒÂ£o 
# ÃƒÂ  primeira, embora as diferenÃƒÂ§as sejam pequenas.

## g) 

confint(reg4, level=0.95)

## h)

par(mfrow=c(2,2))
plot(reg4)

# HÃƒÂ¡ evidÃƒÂªncias de high leverage se considerarmos os valores prÃƒÂ³ximos de 3 no grÃƒÂ¡fico de leverage.

## ExercÃƒ­cio 4 (13)


##a)
set.seed(1)
x=rnorm(100)

##b)

eps = rnorm(100, 0, sqrt(0.25))

##c)

y = -1 + 0.5*x + eps

## o tamanho de y ÃƒÂ© 100. Beta 0 ÃƒÂ© -1 e Beta1 ÃƒÂ© 0.5.

## d)

plot(x, y)

## observa-se uma correlaÃƒÂ§ÃƒÂ£o positiva e ascendente entre as variÃƒÂ¡veis.

## e)

regz=lm(y ~ x)
summary(regz)


# observa-se uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor ÃƒÂ© menor 
# do que 0.05 (pode-se rejeitar a hipÃƒÂ³tese nula).
# O acrÃƒÂ©scimo de uma unidade em x implica um aumento de 0.499 em y.
# comparando os valores, podemos perceber que ambos os modelos possuem valores para B0 e B1 similares.

## f)

abline(regz, col="red", lwd=2)
#ÃƒÂ© a reta da correlaÃƒÂ§ÃƒÂ£o seguindo o mÃƒÂ©todo do
# mÃƒ­nimos quadrados ordinÃƒÂ¡rios

# sendo a fÃƒÂ³rmula para a linha de regressÃƒÂ£o populacional Y = B0 + B1X, podemos dizer que a reta
# serÃƒÂ¡ baseada na funÃƒÂ§ÃƒÂ£o criada na letra c. Dessa forma, temos a equaÃƒÂ§ÃƒÂ£o para essa linha:

ypop = -1 + 0.5*x

# traÃƒÂ§ando a linha

abline(-1, 0.5, col="blue", lwd=2)

legend(1, -1, legend=c("Reta OLS", "Reta Pop."), col=c("red", "blue"), lty=1:5, cex=0.5)

## g)

regy = lm(y ~ x + I(x^2))
summary(regz)
summary(regy)

# comparando os valores de Residual standard error e Multiple R-Squared, observa-se que a funÃƒÂ§ÃƒÂ£o
# aumenta levemente seu poder explicativo, jÃƒÂ¡ que o primeiro diminui (4814 > 0.479) e o segundo aumenta
# (0.4674 < 0.4779).
# 
#
# h)

#a) set.seed(1)
x1=rnorm(100)
#b) 
eps1 = rnorm(100, 0, sqrt(0.1))
# c) 
y1 = -1 + 0.5*x1 + eps1 #o tamanho de y ÃƒÂ© 100. Beta 0 ÃƒÂ© -1 e Beta1 ÃƒÂ© 0.5
#d) 
plot(x1, y1) #observa-se uma correlaÃƒÂ§ÃƒÂ£o positiva e ascendente entre as variÃƒÂ¡veis.
#e) 
regk = lm(y1 ~ x1)
summary(regk)
summary(regz)
#f) 
abline(regk, col="red", lwd=2)
ypop1 = -1 + 0.5*x
abline(-1, 0.5, col="blue", lwd=2)
legend(1, -1, legend=c("Reta OLS", "Reta Pop."), col=c("red", "blue"), lty=1:5, cex=0.5)

## se no primeiro exemplo observava-se que as retas basicamente coincidiam, com a mudanÃƒÂ§a na
#variÃƒÂ¢ncia do modelo, observa-se que a reta OLS, baseada nos mÃƒ­nimos quadrados ordinÃƒÂ¡rios, torna-se
#mais inclinada do que a reta populacional. 
# como se observa ao comparar ambos os modelos, o multiple R-squared ÃƒÂ© muito maior no segundo modelo
#regk (0.7348 > 0.4674), o que significa que seu poder explicativo ÃƒÂ© maior.


# i)

#a) set.seed(1)
x2=rnorm(100)
#b) 
eps2 = rnorm(100, 0, sqrt(0.3))
# c) 
y2 = -1 + 0.5*x2 + eps2
#d) 
plot(x2, y2) #observa-se uma correlaÃƒÂ§ÃƒÂ£o positiva e ascendente entre as variÃƒÂ¡veis.
#e) 
regl = lm(y2 ~ x2)
#f) 
abline(regl, col="red", lwd=2)
ypop1 = -1 + 0.5*x
abline(-1, 0.5, col="blue", lwd=2)
legend(1, -1, legend=c("Reta OLS", "Reta Pop."), col=c("red", "blue"), lty=1:5, cex=0.5)
summary(regl)
summary(regz)


## o contrÃƒÂ¡rio ocorre em relaÃƒÂ§ÃƒÂ£o ao item anterior. aumentando a variÃƒÂ¢ncia, observa-se que o modelo
# adquire um menor poder explicativo, de 52%, menor do que o valor de 73% do item anterior, 
# embora se mantenha maior do que o valor da reta populacional, 
# que possui um multiple R-squared de 0.4674, isto ÃƒÂ©, um poder explicativo de 46,74%.

## ExercÃƒ­cio 5 [15]

##a)
library(MASS)
data(Boston)
head(Boston)
str(Boston)

reg6 = lm(crim ~ zn, data=Boston)
reg7 = lm(crim ~ indus, data=Boston)
reg8 = lm(crim ~ chas, data=Boston)
reg9 = lm(crim ~ nox, data=Boston)
reg10 = lm(crim ~ rm, data=Boston)
reg11 = lm(crim ~ age, data=Boston)
reg12 = lm(crim ~ dis, data=Boston)
reg13 = lm(crim ~ rad, data=Boston)
reg14 = lm(crim ~ tax, data=Boston)
reg15 = lm(crim ~ ptratio, data=Boston)
reg16 = lm(crim ~ black, data=Boston)
reg17 = lm(crim ~ lstat, data=Boston)
reg18 = lm(crim ~ medv , data=Boston)
??(Boston)

summary(reg6)
# HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para zn ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o, contudo, ÃƒÂ© negativa.
summary(reg7)
#HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para chas ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva.
summary(reg8)
##NÃƒÂ£o hÃƒÂ¡ correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis crim e chas.
summary(reg9)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para nox ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva.
summary(reg10)
##HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para rm ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© negativa.
summary(reg11)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para age ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva.
summary(reg12)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para dis ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© negativa.
summary(reg13)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para rad ÃƒÂ© menor que 0.05.Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva.
summary(reg14)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para tax ÃƒÂ© menor que 0.05.Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva.
summary(reg15)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para ptratio ÃƒÂ© menor que 0.05.Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva.
summary(reg16)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para black ÃƒÂ© menor que 0.05. Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© negativa.
summary(reg17)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para lstat ÃƒÂ© menor que 0.05.Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© positiva
summary(reg18)
## HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre as variÃƒÂ¡veis, jÃƒÂ¡ que o p-valor
#para medv ÃƒÂ© menor que 0.05.Esta correlaÃƒÂ§ÃƒÂ£o ÃƒÂ© negativa.


## b)
reg_completa = lm(crim ~ zn + indus + chas + nox + rm + age + 
                    dis + rad + tax + ptratio + black + lstat + medv, data=Boston)
summary(reg_completa)

# HÃƒÂ¡ uma correlaÃƒÂ§ÃƒÂ£o estatisticamente vÃƒÂ¡lida entre crim e as variÃƒÂ¡veis
# zn, dis, rad, black, medv. Para essas variÃƒÂ¡veis podemos rejeitar a hipÃƒÂ³tese nula.

# c)

# Quando comparamos os dados de a e b observamos que algumas variÃƒÂ¡veis, quando,
# associadas a outras, perdem seu efeito. Se, em um primeiro momento, apenas a 
# variÃƒÂ¡vel chas nÃƒÂ£o apresentava correlaÃƒÂ§ÃƒÂ£o significativa com a taxa de crimes, quan-
# do realizamos uma correlaÃƒÂ§ÃƒÂ£o mÃƒÂºltipla, outras variÃƒÂ¡veis tambÃƒÂ©m deixam de possuir
# correlaÃƒÂ§ÃƒÂ£o estatÃƒ­stica significativa com crim. Se a variÃƒÂ¡vel chas mantÃƒÂ©m sua nÃƒÂ£o correlaÃƒÂ§ÃƒÂ£o, outras 
# variÃƒÂ¡veis, como indus, nox, rm, tax, ptratio e lstat, que antes aparentavam 
# possuir correlaÃƒÂ§ÃƒÂ£o significativa, agora nÃƒÂ£o a apresentam em relaÃƒÂ§ÃƒÂ£o a crim, jÃƒÂ¡ que
# seus p-valores sÃƒÂ£o maiores do que 0.05. 

# Segunda parte
x = c(coefficients(reg6)[2],
      coefficients(reg7)[2],
      coefficients(reg8)[2],
      coefficients(reg9)[2],
      coefficients(reg10)[2],
      coefficients(reg11)[2],
      coefficients(reg12)[2],
      coefficients(reg13)[2],
      coefficients(reg14)[2],
      coefficients(reg15)[2],
      coefficients(reg16)[2],
      coefficients(reg17)[2],
      coefficients(reg18)[2])
y = coefficients(reg_completa)[2:14]
plot(x, y)

# coeficiente (-10,0) no modelo unilinear e (30, -10) no modelo de regressÃƒÂ£o mÃƒÂºltipla.

# d) 
# ?



## FIM